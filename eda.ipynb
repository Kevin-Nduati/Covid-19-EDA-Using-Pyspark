{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/23 14:36:04 WARN Utils: Your hostname, kevin-H resolves to a loopback address: 127.0.1.1; using 192.168.1.7 instead (on interface wlo1)\n",
      "22/08/23 14:36:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/kevin/anaconda3/envs/pyspark/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/08/23 14:36:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName('Covid19 Data Mining')\\\n",
    "                    .config('spark.sql.debug.maxToStringFields', 2000)\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv('owid-covid-data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 209763 \n",
      " Columns: 67 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Length: {df.count()} \\n Columns: {len(df.columns)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- iso_code: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- total_cases: double (nullable = true)\n",
      " |-- new_cases: double (nullable = true)\n",
      " |-- new_cases_smoothed: double (nullable = true)\n",
      " |-- total_deaths: double (nullable = true)\n",
      " |-- new_deaths: double (nullable = true)\n",
      " |-- new_deaths_smoothed: double (nullable = true)\n",
      " |-- total_cases_per_million: double (nullable = true)\n",
      " |-- new_cases_per_million: double (nullable = true)\n",
      " |-- new_cases_smoothed_per_million: double (nullable = true)\n",
      " |-- total_deaths_per_million: double (nullable = true)\n",
      " |-- new_deaths_per_million: double (nullable = true)\n",
      " |-- new_deaths_smoothed_per_million: double (nullable = true)\n",
      " |-- reproduction_rate: double (nullable = true)\n",
      " |-- icu_patients: double (nullable = true)\n",
      " |-- icu_patients_per_million: double (nullable = true)\n",
      " |-- hosp_patients: double (nullable = true)\n",
      " |-- hosp_patients_per_million: double (nullable = true)\n",
      " |-- weekly_icu_admissions: double (nullable = true)\n",
      " |-- weekly_icu_admissions_per_million: double (nullable = true)\n",
      " |-- weekly_hosp_admissions: double (nullable = true)\n",
      " |-- weekly_hosp_admissions_per_million: double (nullable = true)\n",
      " |-- total_tests: double (nullable = true)\n",
      " |-- new_tests: double (nullable = true)\n",
      " |-- total_tests_per_thousand: double (nullable = true)\n",
      " |-- new_tests_per_thousand: double (nullable = true)\n",
      " |-- new_tests_smoothed: double (nullable = true)\n",
      " |-- new_tests_smoothed_per_thousand: double (nullable = true)\n",
      " |-- positive_rate: double (nullable = true)\n",
      " |-- tests_per_case: double (nullable = true)\n",
      " |-- tests_units: string (nullable = true)\n",
      " |-- total_vaccinations: double (nullable = true)\n",
      " |-- people_vaccinated: double (nullable = true)\n",
      " |-- people_fully_vaccinated: double (nullable = true)\n",
      " |-- total_boosters: double (nullable = true)\n",
      " |-- new_vaccinations: double (nullable = true)\n",
      " |-- new_vaccinations_smoothed: double (nullable = true)\n",
      " |-- total_vaccinations_per_hundred: double (nullable = true)\n",
      " |-- people_vaccinated_per_hundred: double (nullable = true)\n",
      " |-- people_fully_vaccinated_per_hundred: double (nullable = true)\n",
      " |-- total_boosters_per_hundred: double (nullable = true)\n",
      " |-- new_vaccinations_smoothed_per_million: double (nullable = true)\n",
      " |-- new_people_vaccinated_smoothed: double (nullable = true)\n",
      " |-- new_people_vaccinated_smoothed_per_hundred: double (nullable = true)\n",
      " |-- stringency_index: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- population_density: double (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- aged_65_older: double (nullable = true)\n",
      " |-- aged_70_older: double (nullable = true)\n",
      " |-- gdp_per_capita: double (nullable = true)\n",
      " |-- extreme_poverty: double (nullable = true)\n",
      " |-- cardiovasc_death_rate: double (nullable = true)\n",
      " |-- diabetes_prevalence: double (nullable = true)\n",
      " |-- female_smokers: double (nullable = true)\n",
      " |-- male_smokers: double (nullable = true)\n",
      " |-- handwashing_facilities: double (nullable = true)\n",
      " |-- hospital_beds_per_thousand: double (nullable = true)\n",
      " |-- life_expectancy: double (nullable = true)\n",
      " |-- human_development_index: double (nullable = true)\n",
      " |-- excess_mortality_cumulative_absolute: double (nullable = true)\n",
      " |-- excess_mortality_cumulative: double (nullable = true)\n",
      " |-- excess_mortality: double (nullable = true)\n",
      " |-- excess_mortality_cumulative_per_million: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekly_icu_admissions</th>\n",
       "      <th>weekly_icu_admissions_per_million</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>weekly_hosp_admissions</th>\n",
       "      <th>weekly_hosp_admissions_per_million</th>\n",
       "      <th>icu_patients</th>\n",
       "      <th>icu_patients_per_million</th>\n",
       "      <th>...</th>\n",
       "      <th>new_cases_smoothed_per_million</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>new_cases_per_million</th>\n",
       "      <th>total_cases_per_million</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>population</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202886</td>\n",
       "      <td>202886</td>\n",
       "      <td>202630</td>\n",
       "      <td>202630</td>\n",
       "      <td>202630</td>\n",
       "      <td>202610</td>\n",
       "      <td>196125</td>\n",
       "      <td>196125</td>\n",
       "      <td>182078</td>\n",
       "      <td>182078</td>\n",
       "      <td>...</td>\n",
       "      <td>10883</td>\n",
       "      <td>9964</td>\n",
       "      <td>9711</td>\n",
       "      <td>9468</td>\n",
       "      <td>8787</td>\n",
       "      <td>8544</td>\n",
       "      <td>1241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekly_icu_admissions  weekly_icu_admissions_per_million  \\\n",
       "0                 202886                             202886   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                202630                       202630   \n",
       "\n",
       "   excess_mortality_cumulative_per_million  excess_mortality  \\\n",
       "0                                   202630            202610   \n",
       "\n",
       "   weekly_hosp_admissions  weekly_hosp_admissions_per_million  icu_patients  \\\n",
       "0                  196125                              196125        182078   \n",
       "\n",
       "   icu_patients_per_million  ...  new_cases_smoothed_per_million  \\\n",
       "0                    182078  ...                           10883   \n",
       "\n",
       "   new_cases_smoothed  new_cases_per_million  total_cases_per_million  \\\n",
       "0                9964                   9711                     9468   \n",
       "\n",
       "   new_cases  total_cases  population  iso_code  location  date  \n",
       "0       8787         8544        1241         0         0     0  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as func\n",
    "missing_data = df.select([func.count(func.when(func.isnull(c), c)).alias(c) for c in df.columns])\\\n",
    "                                .collect()[0].asDict() \n",
    "missing_data = dict(sorted(missing_data.items(), reverse=True, key=lambda item: item[1]))\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_records([missing_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2020-02-24|\n",
      "|2020-02-25|\n",
      "|2020-02-26|\n",
      "|2020-02-27|\n",
      "|2020-02-28|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('date', func.to_date(func.unix_timestamp(func.col('date'), 'yyy-MM-dd')\\\n",
    "                                        .cast('timestamp')))\n",
    "\n",
    "df.select('date').show(5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ('2021-01-01', '2021-02-28')\n",
    "\n",
    "df = df.where(func.col('date').between(*dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------------+\n",
      "|iso_code|continent|     location|\n",
      "+--------+---------+-------------+\n",
      "|OWID_SAM|     null|South America|\n",
      "|OWID_SAM|     null|South America|\n",
      "|OWID_SAM|     null|South America|\n",
      "|OWID_SAM|     null|South America|\n",
      "|OWID_SAM|     null|South America|\n",
      "+--------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.sort('continent').select('iso_code', 'continent', 'location').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[iso_code: string, continent: string, location: string, date: date, total_cases: double, new_cases: double, new_cases_smoothed: double, total_deaths: double, new_deaths: double, new_deaths_smoothed: double, total_cases_per_million: double, new_cases_per_million: double, new_cases_smoothed_per_million: double, total_deaths_per_million: double, new_deaths_per_million: double, new_deaths_smoothed_per_million: double, reproduction_rate: double, icu_patients: double, icu_patients_per_million: double, hosp_patients: double, hosp_patients_per_million: double, weekly_icu_admissions: double, weekly_icu_admissions_per_million: double, weekly_hosp_admissions: double, weekly_hosp_admissions_per_million: double, total_tests: double, new_tests: double, total_tests_per_thousand: double, new_tests_per_thousand: double, new_tests_smoothed: double, new_tests_smoothed_per_thousand: double, positive_rate: double, tests_per_case: double, tests_units: string, total_vaccinations: double, people_vaccinated: double, people_fully_vaccinated: double, total_boosters: double, new_vaccinations: double, new_vaccinations_smoothed: double, total_vaccinations_per_hundred: double, people_vaccinated_per_hundred: double, people_fully_vaccinated_per_hundred: double, total_boosters_per_hundred: double, new_vaccinations_smoothed_per_million: double, new_people_vaccinated_smoothed: double, new_people_vaccinated_smoothed_per_hundred: double, stringency_index: double, population: double, population_density: double, median_age: double, aged_65_older: double, aged_70_older: double, gdp_per_capita: double, extreme_poverty: double, cardiovasc_death_rate: double, diabetes_prevalence: double, female_smokers: double, male_smokers: double, handwashing_facilities: double, hospital_beds_per_thousand: double, life_expectancy: double, human_development_index: double, excess_mortality_cumulative_absolute: double, excess_mortality_cumulative: double, excess_mortality: double, excess_mortality_cumulative_per_million: double]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna({'continent': 'OWID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|    tests_units|\n",
      "+---------------+\n",
      "|           null|\n",
      "|  people tested|\n",
      "| samples tested|\n",
      "|tests performed|\n",
      "|  units unclear|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('tests_units').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests_units is a variable that idnicates how each country/location reports on the performed tests. For example, in this case, people tested, the reported number of total tests is expected to be lower compared to the same report in the case of tests_performed, since one person can be testedd more than once. This implies that the missing values are due to some countries/locations not providing the relevant information on how they count the total number of daily tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({'tests_units': 'no info'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OutlierDetection(dataframe, features, alpha=1.5):\n",
    "    feat_types = dict(dataframe.dtypes)\n",
    "    if features == 'all':\n",
    "        features = dataframe.columns\n",
    "    \n",
    "    outliers_cols = []\n",
    "    for feat in features:\n",
    "        # quantitative features\n",
    "        if feat_types[feat] == 'double':\n",
    "            Q1, Q3 = dataframe.approxQuantile(feat, [0.25, 0.75], 0)\n",
    "            iqr = Q3 - Q1\n",
    "            lower_bound = Q1 - (iqr * alpha)\n",
    "            upper_bound = Q3 + (iqr * alpha)\n",
    "            outliers_cols.append(func.when(~func.col(feat).between(lower_bound, upper_bound), True)\\\n",
    "                                    .alias(feat + '_outlier'))\n",
    "    outlier_df = dataframe.select(*outliers_cols)\n",
    "    outlier_df = outlier_df.fillna(False)\n",
    "    return outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|new_cases_outlier|\n",
      "+-----------------+\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "|            false|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_df = OutlierDetection(dataframe=df, features = ['new_cases'], alpha = 1.5)\n",
    "out_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[iso_code: string, continent: string, location: string, date: date, total_cases: double, new_cases: double, new_cases_smoothed: double, total_deaths: double, new_deaths: double, new_deaths_smoothed: double, total_cases_per_million: double, new_cases_per_million: double, new_cases_smoothed_per_million: double, total_deaths_per_million: double, new_deaths_per_million: double, new_deaths_smoothed_per_million: double, reproduction_rate: double, icu_patients: double, icu_patients_per_million: double, hosp_patients: double, hosp_patients_per_million: double, weekly_icu_admissions: double, weekly_icu_admissions_per_million: double, weekly_hosp_admissions: double, weekly_hosp_admissions_per_million: double, total_tests: double, new_tests: double, total_tests_per_thousand: double, new_tests_per_thousand: double, new_tests_smoothed: double, new_tests_smoothed_per_thousand: double, positive_rate: double, tests_per_case: double, tests_units: string, total_vaccinations: double, people_vaccinated: double, people_fully_vaccinated: double, total_boosters: double, new_vaccinations: double, new_vaccinations_smoothed: double, total_vaccinations_per_hundred: double, people_vaccinated_per_hundred: double, people_fully_vaccinated_per_hundred: double, total_boosters_per_hundred: double, new_vaccinations_smoothed_per_million: double, new_people_vaccinated_smoothed: double, new_people_vaccinated_smoothed_per_hundred: double, stringency_index: double, population: double, population_density: double, median_age: double, aged_65_older: double, aged_70_older: double, gdp_per_capita: double, extreme_poverty: double, cardiovasc_death_rate: double, diabetes_prevalence: double, female_smokers: double, male_smokers: double, handwashing_facilities: double, hospital_beds_per_thousand: double, life_expectancy: double, human_development_index: double, excess_mortality_cumulative_absolute: double, excess_mortality_cumulative: double, excess_mortality: double, excess_mortality_cumulative_per_million: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropDuplicates(['location', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, TwoSlopeNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def CustomMap(from_rgb, to_rgb):\n",
    "    # from rgb\n",
    "    r1, g1, b1 = from_rgb\n",
    "    # to rgb\n",
    "    r2, g2, b2 = to_rgb\n",
    "\n",
    "    cdict = {\n",
    "        'red': ((0,r1,r1),\n",
    "                (1, r2, r2)),\n",
    "        'green': ((0, g1, g1),\n",
    "                    1, g2, g2),\n",
    "        'blue': ((0, b1, b1),\n",
    "                (1, b2, b2))\n",
    "    }\n",
    "    cmap = LinearSegmentedColormap('custom_cmap', cdict)\n",
    "    return cmap\n",
    "\n",
    "\n",
    "myCmap = CustomMap([1.0, 1.0, 1.0], [72/255, 99/255, 147/255])\n",
    "myCmap_r = CustomMap([72/255, 99/255, 147/255], [1.0, 1.0, 1.0])\n",
    "\n",
    "mycol = (72/255, 99/255, 147/255)\n",
    "mycomplcol = (129/255, 143/255, 163/255)\n",
    "othercol1 = (135/255, 121/255, 215/255)\n",
    "othercol2 = (57/255, 119/255, 171/255)\n",
    "othercol3 = (68/255, 81/255, 91/255)\n",
    "othercol4 = (73/255, 149/255, 139/255)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16a1e63d911eff1aab37ec58c6e1ea235f3cb3c12a1ea58834ac723c2586ab7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
